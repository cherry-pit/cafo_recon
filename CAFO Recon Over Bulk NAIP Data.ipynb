{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94aaa721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import rasterio\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "os.environ['PROJ_LIB'] = '/usr/share/proj'\n",
    "os.environ['GDAL_DATA'] = '/usr/include/gdal'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa888031",
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_order_name = 'Bulk Order Noel, MO' \n",
    "\n",
    "projectName = bulk_order_name[len('Bulk Order')+1:]\n",
    "rawimageDirectory = f'/media/user/c250/bda/{bulk_order_name}/NAIP'\n",
    "filename_ending_to_look_for = 'tif'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if projectName not in os.listdir():\n",
    "    os.mkdir(projectName)\n",
    "    \n",
    "if 'images_to_check' not in os.listdir(projectName): \n",
    "    os.mkdir(f'{projectName}/images_to_check')\n",
    "    \n",
    "class_names = ['cafo', 'notcafo']\n",
    "model = load_model('CAFO_model_3-29.h5');\n",
    "\n",
    "df = pd.DataFrame(columns=['x','y','imageID','cat','epsgCoords', 'lat', 'long'])\n",
    "\n",
    "imagesToOperateOn = []\n",
    "for file in os.listdir(f'{rawimageDirectory}'):\n",
    "    if file[-3:] == filename_ending_to_look_for:\n",
    "        imagesToOperateOn.append(f'{rawimageDirectory}/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f38895d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9929577464788732\n",
      "Found\n",
      "Found\n",
      "Found\n"
     ]
    }
   ],
   "source": [
    "def Operation(filename):\n",
    "    \n",
    "    #opening a jp2 image and working with it as an array\n",
    "    src = rasterio.open(f'{filename}') #  ,  driver='JP2OpenJPEG')\n",
    "\n",
    "    srcRead = src.read()[:3,:,:].swapaxes(0, 1).swapaxes(1, 2)\n",
    "    srcCRS = src.crs\n",
    "    srcShape = srcRead.shape\n",
    "\n",
    "    # keeping only white parts of the photo\n",
    "    img = cv2.cvtColor(srcRead, cv2.COLOR_BGR2RGB)   # BGR -> RGB\n",
    "    ret, mask = cv2.threshold(img[:, :,2], 200, 200, cv2.THRESH_BINARY)\n",
    "\n",
    "    mask3 = np.zeros_like(img)\n",
    "    mask3[:, :, 0] = mask\n",
    "    mask3[:, :, 1] = mask\n",
    "    mask3[:, :, 2] = mask\n",
    "\n",
    "    img = cv2.bitwise_and(img, mask3)\n",
    "\n",
    "    # getting rid of smaller white spots on the photo and making it to binary\n",
    "    kernel = np.ones((10,10), np.uint8)\n",
    "    img = cv2.erode(img, kernel, iterations=1)\n",
    "    img = cv2.threshold(img , 140, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # filtering out white spots that are close to each other and saving their indicies to a numpy array\n",
    "    indicesToCheck = np.array(np.nonzero(img[:,:,0] > 0)) # take every white spot\n",
    "    filter_ = np.diff(indicesToCheck) > 10 # only look at white spots that are far from each other\n",
    "    indicesToCheck = indicesToCheck.transpose()[:-1,:][filter_[1] & filter_[0]] # apply the distance filter to the original array\n",
    "    \n",
    "    # here we add the indicies around areas of interest to ensure that the object of interest is observed a few different ways\n",
    "    for i in indicesToCheck:\n",
    "        iY = i[0]\n",
    "        iX = i[1]\n",
    "\n",
    "        for n in range(0,480,80): # this should be changed acccordingly depending on input images\n",
    "            iY_prime = iY + n\n",
    "            iX_prime = iX + n\n",
    "            indicesToCheck = np.append(indicesToCheck, np.array( [[iY_prime, iX_prime]] ),axis=0)\n",
    "\n",
    "            iY_prime = iY - n\n",
    "            iX_prime = iX + n\n",
    "            indicesToCheck = np.append(indicesToCheck, np.array( [[iY_prime, iX_prime]] ),axis=0)\n",
    "\n",
    "            iY_prime = iY + n\n",
    "            iX_prime = iX - n\n",
    "            indicesToCheck = np.append(indicesToCheck, np.array( [[iY_prime, iX_prime]] ),axis=0)\n",
    "\n",
    "            iY_prime = iY - n\n",
    "            iX_prime = iX - n\n",
    "            indicesToCheck = np.append(indicesToCheck, np.array( [[iY_prime, iX_prime]] ),axis=0)           \n",
    "    \n",
    "    step = 299 # this is a good step for jp2 compressed NAIP data\n",
    "\n",
    "    \n",
    "    \n",
    "    # this loop will go over the indices of interestest found above and will append the indicies that detect something to a list\n",
    "    DETECTED_COORDS = []\n",
    "    for cords in indicesToCheck:\n",
    "        \n",
    "        #print(cords)\n",
    "        \n",
    "        y = cords[0]\n",
    "        x = cords[1]\n",
    "        \n",
    "        # ensuring that any of the slices we make on the larger image array are within the bounds of that larger image array\n",
    "        \n",
    "        if x < 0:\n",
    "            x = 0\n",
    "            \n",
    "        if y < 0:\n",
    "            y = 0\n",
    "\n",
    "        if y + step> srcShape[0]:\n",
    "            y = srcShape[0]-1\n",
    "            \n",
    "        if x + step> srcShape[1]:\n",
    "            x = srcShape[1]-1\n",
    "        \n",
    "        # slicing the original color image to predict its contents\n",
    "        subArray = srcRead[y:y+step, x:x+step, :]\n",
    "\n",
    "        # here we send each channel to 255 or zero\n",
    "        subArrayModified = cv2.threshold( subArray , 170, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # here we will only look at sub images that have significant amount of bright color in their image\n",
    "        ret, mask = cv2.threshold( subArrayModified[:, :,2], 200, 200, cv2.THRESH_BINARY)\n",
    "        mask3 = np.zeros_like(subArrayModified)\n",
    "        mask3[:, :, 0] = mask\n",
    "        mask3[:, :, 1] = mask\n",
    "        mask3[:, :, 2] = mask\n",
    "        subArrayModified = cv2.bitwise_and(subArrayModified, mask3)\n",
    "\n",
    "        # we then make any colors white and check waht percent white is in the image\n",
    "        subArrayModified = np.absolute(subArrayModified)\n",
    "        subArrayModified[:,:,0][subArrayModified[:,:,1] > 0] = 255\n",
    "        subArrayModified[:,:,0][subArrayModified[:,:,2] > 0] = 255\n",
    "\n",
    "        percentWhite = (subArrayModified[:,:,0]/255).sum() / (subArrayModified[:,:,0].size) # 10 percent or more seems to be about right\n",
    "\n",
    "        if percentWhite > 0.1:\n",
    "        \n",
    "            # making sure the slice has a significant amount of pixel information in it\n",
    "            if subArray.shape[0] * subArray.shape[1] < (100*100):\n",
    "                break\n",
    "\n",
    "            # resizing the image to the size that the model was trained on\n",
    "            subArray = cv2.resize(subArray, (299,299), interpolation = cv2.INTER_AREA)\n",
    "            subArray = tf.expand_dims(subArray, axis=0) \n",
    "\n",
    "            # prediting the contents and assiging a category\n",
    "            predictions = model.predict(subArray)\n",
    "\n",
    "            # if a prediction is close then it will air on the side of caution and assign a prediction that the site is of interest\n",
    "            scores = tf.nn.softmax(predictions[0]).numpy()\n",
    "            scoreFilter = scores.max() - scores < 0.15\n",
    "            if scoreFilter.sum() == 1:\n",
    "                cat = np.array(class_names)[scoreFilter][0]\n",
    "            else:\n",
    "                classNamesFilter = np.array(class_names)[scoreFilter] != 'notcafo'\n",
    "                cat = np.array(class_names)[scoreFilter][classNamesFilter][0]\n",
    "\n",
    "            if cat != 'notcafo':\n",
    "\n",
    "                DETECTED_COORDS.append([y, x])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def ClusterReduction(array): # takes a numpy array and returns an array of reduced size by removing coords in close proximity\n",
    "        # here we create a lists of clusters that are close to each other to decrease the amount of photos that we save for further processing\n",
    "        DETECTED_COORDS = array\n",
    "        clusters = []\n",
    "        for coord in DETECTED_COORDS:\n",
    "            distances = np.sqrt((abs(coord - DETECTED_COORDS)**2).sum(axis=1))\n",
    "\n",
    "            #clusters.append(DETECTED_COORDS[distances < 299*2])   # this is the buffer change is occordingling\n",
    "            clusters.append( DETECTED_COORDS[distances < 299 * 1.5] )\n",
    "\n",
    "\n",
    "        # here we choose the most central coordinate in each cluster to keep\n",
    "        CoordsToKeep = []\n",
    "        for cluster in clusters:\n",
    "            lowestClusterDistance = 999    \n",
    "            for coord in cluster:\n",
    "                distances = np.sqrt((abs(coord - cluster)**2).sum(axis=1))\n",
    "                averageDistanceToNeighbors = distances.mean()\n",
    "\n",
    "                if averageDistanceToNeighbors < lowestClusterDistance:\n",
    "                    lowestClusterDistance = averageDistanceToNeighbors\n",
    "                    coordToKeep = coord\n",
    "\n",
    "            CoordsToKeep.append(coordToKeep)\n",
    "\n",
    "        # np.unique throws an error if the list is empty so we check here that is it not empty\n",
    "        if CoordsToKeep:\n",
    "            CoordsToKeep = np.unique(CoordsToKeep, axis=0)\n",
    "\n",
    "        return CoordsToKeep\n",
    "\n",
    "    DETECTED_COORDS = np.array(DETECTED_COORDS)\n",
    "    for n in range(4): # ClusterReduction is run mulitple times as some coords get caught in mulitple clusters\n",
    "        DETECTED_COORDS = ClusterReduction(DETECTED_COORDS)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    for KEPTCoord in DETECTED_COORDS:\n",
    "\n",
    "        x = KEPTCoord[1]\n",
    "        y = KEPTCoord[0]\n",
    "        \n",
    "        subArray = srcRead[y:y+step, x:x+step, :]\n",
    "        # making sure the slice has a significant amount of pixel information in it\n",
    "        if subArray.shape[0] * subArray.shape[1] < (100*100):\n",
    "            break\n",
    "        # resizing the image to the size that the model was trained on\n",
    "        subArray = cv2.resize(subArray, (299,299), interpolation = cv2.INTER_AREA)        \n",
    "        \n",
    "        epsgCoords = rasterio.transform.xy(src.transform, y+int(step/2), x+int(step/2)) # here we add a bit to get the transformed pixle coords at the center of the saved photo\n",
    "        lat = epsgCoords[1]\n",
    "        long = epsgCoords[0]     \n",
    "\n",
    "        # creating a unqiue image id and saving the photo to a folder so it can later be gone over to ensure its contents are correct\n",
    "        imgID = filename[-10:] + '_' + str(x) + '_' + str(y)\n",
    "        cv2.imwrite(f'{projectName}/images_to_check/{imgID}.png', cv2.cvtColor(subArray, cv2.COLOR_RGB2BGR) )\n",
    "        df.loc[len(df)] = y, x, imgID, cat, epsgCoords, lat, long\n",
    "        print('Found')          \n",
    "\n",
    "            \n",
    "    srcCRS = src.crs\n",
    "    src.close()\n",
    "    return srcCRS\n",
    "\n",
    "    ####\n",
    "\n",
    "for image in imagesToOperateOn:\n",
    "    clear_output(wait=True)\n",
    "    print(imagesToOperateOn.index(image)/(len(imagesToOperateOn)))\n",
    "    srcCRS = Operation(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f07fb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rasterio.open(f'{image}')\n",
    "df.to_csv(f'{projectName}/{projectName}_{srcCRS}_unfiltered.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "15d91decb3dec4900a0b202f116d11bafb2684fce47562dc9acab7c1752e20dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
